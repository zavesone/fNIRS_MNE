{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits: Andrei Miroshnikov andrej.miroshnikow@gmail.com\n",
    "# Useful links:\n",
    "# https://mne.tools/stable/auto_tutorials/index.html\n",
    "# https://mne.tools/mne-nirs/stable/auto_examples/index.html\n",
    "\n",
    "############################################################\n",
    "\n",
    "#installs for EEG and fNIRS processing. uncomment if needed to install in Jupyter\n",
    "\n",
    "# !pip install mne\n",
    "# !pip install mne_nirs\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfQYeukhWh27",
    "outputId": "6ef2c985-80c8-468e-efec-b1aa73fb1ded"
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import compress\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "from mne.preprocessing.nirs import optical_density, beer_lambert_law\n",
    "\n",
    "from mne.preprocessing.nirs import (optical_density,\n",
    "                                    temporal_derivative_distribution_repair)\n",
    "from mne_nirs.signal_enhancement import enhance_negative_correlation, short_channel_regression\n",
    "from mne import Epochs, events_from_annotations\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read our fNIRS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnirs_dirname = '/mnt/diskus/fNIRS data ME_MI_TS_TI_SA/AB/AB_ME'\n",
    "raw_intensity = mne.io.read_raw_nirx(fnirs_dirname)\n",
    "raw_intensity.drop_channels(['S2_D4 760', 'S2_D4 850'])\n",
    "\n",
    "raw_info = raw_intensity.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can look at our data and sensors' positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_intensity.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensors_pos = mne.viz.plot_sensors(raw_info, kind='select')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_we_can_pick = ['S5_D6 760',\n",
    " 'S5_D6 850',\n",
    " 'S5_D12 760',\n",
    " 'S5_D12 850',\n",
    " 'S6_D3 760',\n",
    " 'S6_D3 850',\n",
    " 'S6_D6 760',\n",
    " 'S6_D6 850',\n",
    " 'S6_D7 760',\n",
    " 'S6_D7 850',\n",
    " 'S6_D10 760',\n",
    " 'S6_D10 850',\n",
    " 'S6_D13 760',\n",
    " 'S6_D13 850',\n",
    " 'S7_D4 760',\n",
    " 'S7_D4 850',\n",
    " 'S7_D8 760',\n",
    " 'S7_D8 850',\n",
    " 'S7_D9 760',\n",
    " 'S7_D9 850',\n",
    " 'S7_D11 760',\n",
    " 'S7_D11 850',\n",
    " 'S7_D14 760',\n",
    " 'S7_D14 850',\n",
    " 'S8_D9 760',\n",
    " 'S8_D9 850',\n",
    " 'S8_D15 760',\n",
    " 'S8_D15 850',\n",
    " 'S9_D6 760',\n",
    " 'S9_D6 850',\n",
    " 'S9_D10 760',\n",
    " 'S9_D10 850',\n",
    " 'S9_D12 760',\n",
    " 'S9_D12 850',\n",
    " 'S9_D13 760',\n",
    " 'S9_D13 850',\n",
    " 'S9_D18 760',\n",
    " 'S9_D18 850',\n",
    " 'S10_D7 760',\n",
    " 'S10_D7 850',\n",
    " 'S10_D13 760',\n",
    " 'S10_D13 850',\n",
    " 'S10_D16 760',\n",
    " 'S10_D16 850',\n",
    " 'S10_D19 760',\n",
    " 'S10_D19 850',\n",
    " 'S11_D8 760',\n",
    " 'S11_D8 850',\n",
    " 'S11_D14 760',\n",
    " 'S11_D14 850',\n",
    " 'S11_D17 760',\n",
    " 'S11_D17 850',\n",
    " 'S11_D20 760',\n",
    " 'S11_D20 850',\n",
    " 'S12_D9 760',\n",
    " 'S12_D9 850',\n",
    " 'S12_D11 760',\n",
    " 'S12_D11 850',\n",
    " 'S12_D14 760',\n",
    " 'S12_D14 850',\n",
    " 'S12_D15 760',\n",
    " 'S12_D15 850',\n",
    " 'S12_D21 760',\n",
    " 'S12_D21 850',\n",
    " 'S13_D12 760',\n",
    " 'S13_D12 850',\n",
    " 'S13_D18 760',\n",
    " 'S13_D18 850',\n",
    " 'S13_D34 760',\n",
    " 'S13_D34 850',\n",
    " 'S14_D15 760',\n",
    " 'S14_D15 850',\n",
    " 'S14_D21 760',\n",
    " 'S14_D21 850',\n",
    " 'S14_D35 760',\n",
    " 'S14_D35 850',\n",
    " 'S15_D12 760',\n",
    " 'S15_D12 850',\n",
    " 'S15_D18 760',\n",
    " 'S15_D18 850',\n",
    " 'S15_D22 760',\n",
    " 'S15_D22 850',\n",
    " 'S16_D13 760',\n",
    " 'S16_D13 850',\n",
    " 'S16_D16 760',\n",
    " 'S16_D16 850',\n",
    " 'S16_D18 760',\n",
    " 'S16_D18 850',\n",
    " 'S16_D19 760',\n",
    " 'S16_D19 850',\n",
    " 'S16_D23 760',\n",
    " 'S16_D23 850',\n",
    " 'S17_D14 760',\n",
    " 'S17_D14 850',\n",
    " 'S17_D17 760',\n",
    " 'S17_D17 850',\n",
    " 'S17_D20 760',\n",
    " 'S17_D20 850',\n",
    " 'S17_D21 760',\n",
    " 'S17_D21 850',\n",
    " 'S17_D24 760',\n",
    " 'S17_D24 850',\n",
    " 'S18_D15 760',\n",
    " 'S18_D15 850',\n",
    " 'S18_D21 760',\n",
    " 'S18_D21 850',\n",
    " 'S18_D25 760',\n",
    " 'S18_D25 850',\n",
    " 'S19_D18 760',\n",
    " 'S19_D18 850',\n",
    " 'S19_D22 760',\n",
    " 'S19_D22 850',\n",
    " 'S20_D18 760',\n",
    " 'S20_D18 850',\n",
    " 'S20_D23 760',\n",
    " 'S20_D23 850',\n",
    " 'S20_D36 760',\n",
    " 'S20_D36 850',\n",
    " 'S21_D21 760',\n",
    " 'S21_D21 850',\n",
    " 'S21_D24 760',\n",
    " 'S21_D24 850',\n",
    " 'S21_D37 760',\n",
    " 'S21_D37 850',\n",
    " 'S22_D21 760',\n",
    " 'S22_D21 850',\n",
    " 'S22_D25 760',\n",
    " 'S22_D25 850',\n",
    " 'S23_D18 760',\n",
    " 'S23_D18 850',\n",
    " 'S23_D22 760',\n",
    " 'S23_D22 850',\n",
    " 'S23_D23 760',\n",
    " 'S23_D23 850',\n",
    " 'S24_D19 760',\n",
    " 'S24_D19 850',\n",
    " 'S25_D20 760',\n",
    " 'S25_D20 850',\n",
    " 'S26_D21 760',\n",
    " 'S26_D21 850',\n",
    " 'S26_D24 760',\n",
    " 'S26_D24 850',\n",
    " 'S26_D25 760',\n",
    " 'S26_D25 850']\n",
    "\n",
    "hb_channels_we_can_pick = ['S5_D6 hbo',\n",
    " 'S5_D6 hbr',\n",
    " 'S5_D12 hbo',\n",
    " 'S5_D12 hbr',\n",
    " 'S6_D3 hbo',\n",
    " 'S6_D3 hbr',\n",
    " 'S6_D6 hbo',\n",
    " 'S6_D6 hbr',\n",
    " 'S6_D7 hbo',\n",
    " 'S6_D7 hbr',\n",
    " 'S6_D10 hbo',\n",
    " 'S6_D10 hbr',\n",
    " 'S6_D13 hbo',\n",
    " 'S6_D13 hbr',\n",
    " 'S7_D4 hbo',\n",
    " 'S7_D4 hbr',\n",
    " 'S7_D8 hbo',\n",
    " 'S7_D8 hbr',\n",
    " 'S7_D9 hbo',\n",
    " 'S7_D9 hbr',\n",
    " 'S7_D11 hbo',\n",
    " 'S7_D11 hbr',\n",
    " 'S7_D14 hbo',\n",
    " 'S7_D14 hbr',\n",
    " 'S8_D9 hbo',\n",
    " 'S8_D9 hbr',\n",
    " 'S8_D15 hbo',\n",
    " 'S8_D15 hbr',\n",
    " 'S9_D6 hbo',\n",
    " 'S9_D6 hbr',\n",
    " 'S9_D10 hbo',\n",
    " 'S9_D10 hbr',\n",
    " 'S9_D12 hbo',\n",
    " 'S9_D12 hbr',\n",
    " 'S9_D13 hbo',\n",
    " 'S9_D13 hbr',\n",
    " 'S9_D18 hbo',\n",
    " 'S9_D18 hbr',\n",
    " 'S10_D7 hbo',\n",
    " 'S10_D7 hbr',\n",
    " 'S10_D13 hbo',\n",
    " 'S10_D13 hbr',\n",
    " 'S10_D16 hbo',\n",
    " 'S10_D16 hbr',\n",
    " 'S10_D19 hbo',\n",
    " 'S10_D19 hbr',\n",
    " 'S11_D8 hbo',\n",
    " 'S11_D8 hbr',\n",
    " 'S11_D14 hbo',\n",
    " 'S11_D14 hbr',\n",
    " 'S11_D17 hbo',\n",
    " 'S11_D17 hbr',\n",
    " 'S11_D20 hbo',\n",
    " 'S11_D20 hbr',\n",
    " 'S12_D9 hbo',\n",
    " 'S12_D9 hbr',\n",
    " 'S12_D11 hbo',\n",
    " 'S12_D11 hbr',\n",
    " 'S12_D14 hbo',\n",
    " 'S12_D14 hbr',\n",
    " 'S12_D15 hbo',\n",
    " 'S12_D15 hbr',\n",
    " 'S12_D21 hbo',\n",
    " 'S12_D21 hbr',\n",
    " 'S13_D12 hbo',\n",
    " 'S13_D12 hbr',\n",
    " 'S13_D18 hbo',\n",
    " 'S13_D18 hbr',\n",
    " 'S13_D34 hbo',\n",
    " 'S13_D34 hbr',\n",
    " 'S14_D15 hbo',\n",
    " 'S14_D15 hbr',\n",
    " 'S14_D21 hbo',\n",
    " 'S14_D21 hbr',\n",
    " 'S14_D35 hbo',\n",
    " 'S14_D35 hbr',\n",
    " 'S15_D12 hbo',\n",
    " 'S15_D12 hbr',\n",
    " 'S15_D18 hbo',\n",
    " 'S15_D18 hbr',\n",
    " 'S15_D22 hbo',\n",
    " 'S15_D22 hbr',\n",
    " 'S16_D13 hbo',\n",
    " 'S16_D13 hbr',\n",
    " 'S16_D16 hbo',\n",
    " 'S16_D16 hbr',\n",
    " 'S16_D18 hbo',\n",
    " 'S16_D18 hbr',\n",
    " 'S16_D19 hbo',\n",
    " 'S16_D19 hbr',\n",
    " 'S16_D23 hbo',\n",
    " 'S16_D23 hbr',\n",
    " 'S17_D14 hbo',\n",
    " 'S17_D14 hbr',\n",
    " 'S17_D17 hbo',\n",
    " 'S17_D17 hbr',\n",
    " 'S17_D20 hbo',\n",
    " 'S17_D20 hbr',\n",
    " 'S17_D21 hbo',\n",
    " 'S17_D21 hbr',\n",
    " 'S17_D24 hbo',\n",
    " 'S17_D24 hbr',\n",
    " 'S18_D15 hbo',\n",
    " 'S18_D15 hbr',\n",
    " 'S18_D21 hbo',\n",
    " 'S18_D21 hbr',\n",
    " 'S18_D25 hbo',\n",
    " 'S18_D25 hbr',\n",
    " 'S19_D18 hbo',\n",
    " 'S19_D18 hbr',\n",
    " 'S19_D22 hbo',\n",
    " 'S19_D22 hbr',\n",
    " 'S20_D18 hbo',\n",
    " 'S20_D18 hbr',\n",
    " 'S20_D23 hbo',\n",
    " 'S20_D23 hbr',\n",
    " 'S20_D36 hbo',\n",
    " 'S20_D36 hbr',\n",
    " 'S21_D21 hbo',\n",
    " 'S21_D21 hbr',\n",
    " 'S21_D24 hbo',\n",
    " 'S21_D24 hbr',\n",
    " 'S21_D37 hbo',\n",
    " 'S21_D37 hbr',\n",
    " 'S22_D21 hbo',\n",
    " 'S22_D21 hbr',\n",
    " 'S22_D25 hbo',\n",
    " 'S22_D25 hbr',\n",
    " 'S23_D18 hbo',\n",
    " 'S23_D18 hbr',\n",
    " 'S23_D22 hbo',\n",
    " 'S23_D22 hbr',\n",
    " 'S23_D23 hbo',\n",
    " 'S23_D23 hbr',\n",
    " 'S24_D19 hbo',\n",
    " 'S24_D19 hbr',\n",
    " 'S25_D20 hbo',\n",
    " 'S25_D20 hbr',\n",
    " 'S26_D21 hbo',\n",
    " 'S26_D21 hbr',\n",
    " 'S26_D24 hbo',\n",
    " 'S26_D24 hbr',\n",
    " 'S26_D25 hbo',\n",
    " 'S26_D25 hbr']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go from raw intensity to optical density and enchance our signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_od = optical_density(raw_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_od_shorts = raw_od.copy()\n",
    "raw_od_shorts = mne_nirs.channels.get_short_channels(raw_od_shorts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check scalp coupling index in short and long channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_to_sci = raw_od_shorts\n",
    "sci = mne.preprocessing.nirs.scalp_coupling_index(raw_to_sci)\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "ax.hist(sci)\n",
    "ax.set(xlabel=\"Scalp Coupling Index\", ylabel=\"Count\", xlim=[0, 1])\n",
    "bad_shorts_sci = list(compress(raw_to_sci.ch_names, sci < 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we remove bad short channels\n",
    "raw_od.drop_channels(bad_shorts_sci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_to_sci = raw_od\n",
    "sci = mne.preprocessing.nirs.scalp_coupling_index(raw_to_sci)\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "ax.hist(sci)\n",
    "ax.set(xlabel=\"Scalp Coupling Index\", ylabel=\"Count\", xlim=[0, 1])\n",
    "bad_long_sci = list(compress(raw_to_sci.ch_names, sci < 0.5))\n",
    "raw_od.info['bads'] = bad_long_sci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform TDDR and short channels regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_od = temporal_derivative_distribution_repair(raw_od) #repairs movement artifacts\n",
    "raw_od = short_channel_regression(raw_od)\n",
    "raw_od.pick_channels(channels_we_can_pick)\n",
    "raw_od.interpolate_bads(reset_bads=False, method=dict(fnirs='nearest'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's convert our optical density to haemoglobin concentration. We will also perform negative correlation enchancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_haemo = mne.preprocessing.nirs.beer_lambert_law(raw_od, ppf=0.1) #from wavelength to HbO\\HbR\n",
    "raw_haemo = mne_nirs.channels.get_long_channels(raw_haemo)\n",
    "raw_haemo = enhance_negative_correlation(raw_haemo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering -- one of trickier parts of fNIRS data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = raw_haemo.plot_psd(average=True)\n",
    "fig.suptitle('Before filtering', weight='bold', size='x-large')\n",
    "fig.subplots_adjust(top=0.88)\n",
    "\n",
    "l_freq = 0.01\n",
    "h_freq = 0.1\n",
    "h_trans_bandwidth = 0.1\n",
    "l_trans_bandwidth = 0.01\n",
    "\n",
    "raw_haemo = raw_haemo.filter(l_freq, h_freq, \n",
    "                             h_trans_bandwidth=h_trans_bandwidth,\n",
    "                             l_trans_bandwidth=l_trans_bandwidth\n",
    "                            )\n",
    "fig = raw_haemo.plot_psd(average=True)\n",
    "fig.suptitle('After filtering', weight='bold', size='x-large')\n",
    "fig.subplots_adjust(top=0.88)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's also resample to make it more convenient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SFREQ = 1\n",
    "raw_haemo.resample(SFREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell is about selecting a subgroup of channels. In our case, we wanted to select channels around C3 and C4 10-20 leads (corresponding locations are listed). So we end up having a pair of groups of ~20 long channels corresponding for each side's sensorimotor zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "pzVV70rR7TGV",
    "outputId": "fd38e858-eebe-4abf-bae1-27452d99a23d"
   },
   "outputs": [],
   "source": [
    "C3_chans_of_interest_hbo =  ['S9_D13 hbo',\n",
    "'S9_D18 hbo',\n",
    "'S10_D13 hbo',\n",
    "'S10_D16 hbo',\n",
    "'S10_D19 hbo',\n",
    "'S13_D18 hbo',\n",
    "'S16_D13 hbo',\n",
    "'S16_D16 hbo',\n",
    "'S16_D18 hbo',\n",
    "'S16_D19 hbo',\n",
    "'S16_D23 hbo',\n",
    "'S24_D19 hbo']\n",
    "C3_chans_of_interest_hbr = [i.replace('hbo', 'hbr') for i in C3_chans_of_interest_hbo]\n",
    "\n",
    "C4_chans_of_interest_hbo =  ['S11_D14 hbo',\n",
    "'S11_D17 hbo',\n",
    "'S11_D20 hbo',\n",
    "'S12_D14 hbo',\n",
    "'S12_D21 hbo',\n",
    "'S17_D14 hbo',\n",
    "'S17_D17 hbo',\n",
    "'S17_D20 hbo',\n",
    "'S17_D21 hbo',\n",
    "'S17_D24 hbo',\n",
    "'S18_D15 hbo',\n",
    "'S25_D20 hbo']\n",
    "C4_chans_of_interest_hbr = [i.replace('hbo', 'hbr') for i in C4_chans_of_interest_hbo]\n",
    "\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we make a transition from continiuous data to segmented data -- we will make epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, ids = mne.events_from_annotations(raw_haemo)\n",
    "ids[\"Rest\"] = 2\n",
    "ids[\"Sensorimotor\"] = 1\n",
    "\n",
    "try:\n",
    "    ids.pop(\"2.0\")\n",
    "    ids.pop(\"1.0\")\n",
    "except:\n",
    "    ids.pop(\"2\")\n",
    "    ids.pop(\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can set different epochs parameters like length, baseline or else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = 0, 14\n",
    "baseline = (0, 0)\n",
    "\n",
    "# reject_criteria = dict(hbo=35e-6)\n",
    "\n",
    "epochs = mne.Epochs(raw_haemo, events, event_id=ids,\n",
    "                    tmin=tmin, tmax=tmax,\n",
    "#                     reject=reject_criteria, \n",
    "#                     reject_by_annotation=True,\n",
    "                     baseline=baseline, preload=True,\n",
    "                    detrend=None, verbose=True)\n",
    "# epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional step but can be of use: a function which will remove extreme epochs in 'remove the outliers' fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_rejector(epochs, criterion='median',\n",
    "                    sfreq=SFREQ, \n",
    "                    time_limits = (4, 12),\n",
    "                    lower=0.10, upper=0.90):\n",
    "\n",
    "    time_limits = (time_limits[0]*sfreq, time_limits[1]*sfreq)\n",
    "    epochs.copy().pick_channels(C3_chans_of_interest_hbo)\n",
    "    epochs_data = epochs.get_data()[:, :, time_limits[0]:time_limits[1]]\n",
    "\n",
    "    if criterion == 'median':\n",
    "\n",
    "        median = np.median(epochs_data, axis=1)\n",
    "        median = np.median(median, axis=1)\n",
    "        lower_quantile = np.quantile(median, lower)\n",
    "        upper_quantile = np.quantile(median, upper)\n",
    "\n",
    "        reject_bool_negative = median < lower_quantile\n",
    "        reject_bool_positive = median > upper_quantile\n",
    "\n",
    "        reject_bool = np.logical_or( \n",
    "                                    reject_bool_negative, \n",
    "                                    reject_bool_positive)\n",
    "    return reject_bool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can set different quantile limits for different states\\epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMR_LOWER_QUANTILE, SMR_UPPER_QUANTILE = 0.1, 0.9\n",
    "REST_LOWER_QUANTILE, REST_UPPER_QUANTILE = 0.1, 0.9\n",
    "time_limits = (4, 13)\n",
    "\n",
    "rest_epochs = epochs[\"Rest\"]\n",
    "smr_epochs = epochs[\"Sensorimotor\"]\n",
    "\n",
    "smr_reject_bool = epochs_rejector(smr_epochs, \n",
    "                                  lower=SMR_LOWER_QUANTILE, \n",
    "                                  upper=SMR_UPPER_QUANTILE, \n",
    "                                  time_limits=time_limits)\n",
    "rest_reject_bool = epochs_rejector(rest_epochs, \n",
    "                                   lower=REST_LOWER_QUANTILE, \n",
    "                                   upper=REST_UPPER_QUANTILE, \n",
    "                                   time_limits=time_limits)\n",
    "\n",
    "#Drop epochs using boolean masks\n",
    "smr_epochs = smr_epochs.drop(smr_reject_bool)\n",
    "rest_epochs = rest_epochs.drop(rest_reject_bool)\n",
    "\n",
    "\n",
    "smr_epochs_data = smr_epochs.get_data()\n",
    "rest_epochs_data = rest_epochs.get_data()\n",
    "\n",
    "evoked_smr = smr_epochs.average()\n",
    "evoked_rest = rest_epochs.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDITION = 'CONDITION'\n",
    "SUBJECT = 'SKOLTECH'\n",
    "averaging_method = 'mean'\n",
    "\n",
    "picks_hbo_left, picks_hbr_left = C3_chans_of_interest_hbo, C3_chans_of_interest_hbr\n",
    "picks_hbo_right, picks_hbr_right = C4_chans_of_interest_hbo, C4_chans_of_interest_hbr\n",
    "\n",
    "\n",
    "\n",
    "evoked_dict_left = {f'{CONDITION}/HbO': smr_epochs.copy().average(picks=picks_hbo_left, method=averaging_method),\n",
    "               f'{CONDITION}/HbR': smr_epochs.copy().average(picks=picks_hbr_left, method=averaging_method),\n",
    "               'Rest/HbO': rest_epochs.copy().average(picks=picks_hbo_left, method=averaging_method),\n",
    "               'Rest/HbR': rest_epochs.copy().average(picks=picks_hbr_left, method=averaging_method)}\n",
    "\n",
    "evoked_dict_right = {f'{CONDITION}/HbO': smr_epochs.copy().average(picks=picks_hbo_right, method=averaging_method),\n",
    "               f'{CONDITION}/HbR': smr_epochs.copy().average(picks=picks_hbr_right, method=averaging_method),\n",
    "               'Rest/HbO': rest_epochs.copy().average(picks=picks_hbo_right, method=averaging_method),\n",
    "               'Rest/HbR': rest_epochs.copy().average(picks=picks_hbr_right, method=averaging_method)}\n",
    "\n",
    "# Rename channels until the encoding of frequency in ch_name is fixed\n",
    "for condition in evoked_dict_left:\n",
    "    evoked_dict_left[condition].rename_channels(lambda x: x[:-4])\n",
    "\n",
    "for condition in evoked_dict_right:\n",
    "    evoked_dict_right[condition].rename_channels(lambda x: x[:-4])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "color_dict = dict(HbO='#AA3377', HbR='b')\n",
    "styles_dict = dict(Rest=dict(linestyle='dashed'))\n",
    "\n",
    "\n",
    "y_min = min(evoked_dict_left[f'{CONDITION}/HbO'].data.min(),\n",
    "            evoked_dict_right[f'{CONDITION}/HbO'].data.min(),()) * 10**6\n",
    "y_max = max(evoked_dict_left[f'{CONDITION}/HbO'].data.max(),\n",
    "            evoked_dict_right[f'{CONDITION}/HbO'].data.max(),()) * 10**6\n",
    "ylim = {'hbo':[y_min, y_max],\n",
    "            'hbr':[y_min, y_max]}\n",
    "\n",
    "left_plot = mne.viz.plot_compare_evokeds(evoked_dict_left,\n",
    "                                         combine=averaging_method,\n",
    "                                         ci=0.95,\n",
    "                                         colors=color_dict,\n",
    "                                         styles=styles_dict,\n",
    "                                         title=f'{CONDITION} and Rest trials LEFT hemisphere\\nSubject {SUBJECT}',\n",
    "                                         axes=axes[0],\n",
    "                                         ylim=ylim,\n",
    "                                         truncate_xaxis=False)  # Use the first subplot axes\n",
    "right_plot = mne.viz.plot_compare_evokeds(evoked_dict_right,\n",
    "                                           combine=averaging_method,\n",
    "                                           ci=0.95,\n",
    "                                           colors=color_dict,\n",
    "                                           styles=styles_dict,\n",
    "                                           title=f'{CONDITION} and Rest trials RIGHT hemisphere\\nSubject {SUBJECT}',\n",
    "                                           axes=axes[1],\n",
    "                                           ylim=ylim,\n",
    "                                           truncate_xaxis=False)  # Use the second subplot axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topomaps_plotter('hbo', smr_epochs=smr_epochs, rest_epochs=rest_epochs, CONDITION=CONDITION, SUBJECT=SUBJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topomaps_plotter(haemo_picks, smr_epochs, rest_epochs, CONDITION, SUBJECT):\n",
    "        times = np.arange(2, 14, 2)\n",
    "        if haemo_picks=='hbo':\n",
    "            topo_haemo = 'HbO'\n",
    "        else:\n",
    "            topo_haemo = 'HbR'\n",
    "\n",
    "        topomap_args = dict(extrapolate='local')\n",
    "        smr_evoked = smr_epochs.average(picks=haemo_picks, method='median')\n",
    "        rest_evoked = rest_epochs.average(picks=haemo_picks, method='median')\n",
    "        vmin = min(smr_evoked.data.min(), rest_evoked.data.min())*10**6\n",
    "        vmax = max(smr_evoked.data.max(), rest_evoked.data.max())*10**6\n",
    "        vlim = (vmin, vmax)\n",
    "        sm = plt.cm.ScalarMappable(cmap='RdBu_r', norm=matplotlib.colors.Normalize(vmin=vmin, vmax=vmax))\n",
    "\n",
    "        # create a figure to contain both topomap plots\n",
    "        fig, axes = plt.subplots(2, len(times), figsize=(14, 7))\n",
    "\n",
    "        # loop through times and plot the topomaps for smr epochs and rest epochs\n",
    "        smr_fig = smr_evoked.plot_topomap(times, axes=axes[0, :],\n",
    "                                colorbar=False,\n",
    "                                show=False,\n",
    "                                **topomap_args)\n",
    "        rest_fig = rest_evoked.plot_topomap(times, axes=axes[1, :],\n",
    "                                show=False,\n",
    "                                colorbar=False,\n",
    "                                **topomap_args)\n",
    "\n",
    "        cbaxes = fig.add_axes([0.095, 0.25, 0.02, 0.5]) # setup colorbar axes. \n",
    "\n",
    "        cbar = plt.colorbar(mappable=sm, cax=cbaxes, pad=0.15, orientation='vertical')\n",
    "        cbar.set_label(f'{topo_haemo} concentration, Δ μM\\L', loc='center', size=12)\n",
    "\n",
    "        fig.subplots_adjust( \n",
    "                            top=0.910, \n",
    "                            bottom=0.06,\n",
    "                            left=0.150, \n",
    "                            right=0.950, \n",
    "                            hspace=0.195, \n",
    "                            wspace=0.0 \n",
    "                        )\n",
    "\n",
    "        x_top, y_top = 0.55, 0.95\n",
    "        x_bottom, y_bottom = 0.55, 0.5\n",
    "\n",
    "        fig.text(\n",
    "                x=x_top, y=y_top, \n",
    "                s=f'{CONDITION} {topo_haemo} changes timeline', \n",
    "                fontsize='x-large', \n",
    "                horizontalalignment='center', \n",
    "                verticalalignment='center' \n",
    "                )\n",
    "        fig.text( \n",
    "                x=x_bottom, y=y_bottom, \n",
    "                s=f'Rest {topo_haemo} changes timeline', \n",
    "                fontsize='x-large', \n",
    "                horizontalalignment='center', \n",
    "                verticalalignment='center'\n",
    "                )#we set a timeline for each epoch"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
